<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Topic 02.1: Building an NLP Pipeline(PART-1) | Bits and Bytes of NLP</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Topic 02.1: Building an NLP Pipeline(PART-1)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A technical blog which cover all Bits and Bytes of NLP." />
<meta property="og:description" content="A technical blog which cover all Bits and Bytes of NLP." />
<link rel="canonical" href="https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/nlp-pipeline/2020/12/26/_12_24_Building_an_NLP_Pipeline(PART_1).html" />
<meta property="og:url" content="https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/nlp-pipeline/2020/12/26/_12_24_Building_an_NLP_Pipeline(PART_1).html" />
<meta property="og:site_name" content="Bits and Bytes of NLP" />
<meta property="og:image" content="https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/images/logo/logo.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-12-26T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/nlp-pipeline/2020/12/26/_12_24_Building_an_NLP_Pipeline(PART_1).html","@type":"BlogPosting","headline":"Topic 02.1: Building an NLP Pipeline(PART-1)","dateModified":"2020-12-26T00:00:00-06:00","datePublished":"2020-12-26T00:00:00-06:00","image":"https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/images/logo/logo.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/nlp-pipeline/2020/12/26/_12_24_Building_an_NLP_Pipeline(PART_1).html"},"description":"A technical blog which cover all Bits and Bytes of NLP.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Bits-and-Bytes-of-NLP/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://shubhangidabral13.github.io/Bits-and-Bytes-of-NLP/feed.xml" title="Bits and Bytes of NLP" /><link rel="shortcut icon" type="image/x-icon" href="/Bits-and-Bytes-of-NLP/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Bits-and-Bytes-of-NLP/">Bits and Bytes of NLP</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Bits-and-Bytes-of-NLP/about/">About Me</a><a class="page-link" href="/Bits-and-Bytes-of-NLP/search/">Search</a><a class="page-link" href="/Bits-and-Bytes-of-NLP/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Topic 02.1: Building an NLP Pipeline(PART-1)</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-12-26T00:00:00-06:00" itemprop="datePublished">
        Dec 26, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Bits-and-Bytes-of-NLP/categories/#nlp-pipeline">nlp-pipeline</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/ShubhangiDabral13/Bits-and-Bytes-of-NLP/tree/master/_notebooks/2020_12_24_Building_an_NLP_Pipeline(PART_1).ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/Bits-and-Bytes-of-NLP/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ShubhangiDabral13/Bits-and-Bytes-of-NLP/master?filepath=_notebooks%2F2020_12_24_Building_an_NLP_Pipeline%28PART_1%29.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Bits-and-Bytes-of-NLP/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ShubhangiDabral13/Bits-and-Bytes-of-NLP/blob/master/_notebooks/2020_12_24_Building_an_NLP_Pipeline(PART_1).ipynb" target="_blank">
        <img class="notebook-badge-image" src="/Bits-and-Bytes-of-NLP/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#DATA-ACQUISITION">DATA ACQUISITION </a>
<ul>
<li class="toc-entry toc-h2"><a href="#1).Scrape-web-pages">1).Scrape web pages </a></li>
<li class="toc-entry toc-h2"><a href="#2).Data-Augmentation">2).Data Augmentation </a>
<ul>
<li class="toc-entry toc-h3"><a href="#a).Back-translation">a).Back translation </a></li>
<li class="toc-entry toc-h3"><a href="#b).Replacing-Entities">b).Replacing Entities </a></li>
<li class="toc-entry toc-h3"><a href="#c).Synonym-Replacement">c).Synonym Replacement </a></li>
<li class="toc-entry toc-h3"><a href="#d).Bigram-flipping">d).Bigram flipping </a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#TEXT-CLEANING">TEXT CLEANING </a>
<ul>
<li class="toc-entry toc-h2"><a href="#HTML-tag-cleaning">HTML tag cleaning </a></li>
<li class="toc-entry toc-h2"><a href="#Unicode-Normalization:">Unicode Normalization: </a></li>
<li class="toc-entry toc-h2"><a href="#Spelling-Correction">Spelling Correction </a></li>
<li class="toc-entry toc-h2"><a href="#System-Specific-Error-Correction">System-Specific Error Correction </a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#Recap">Recap </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020_12_24_Building_an_NLP_Pipeline(PART_1).ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If we were asked to build an NLP application, think about how we would approach doing so at an organization. We would normally walk through the requirements and break the problem down into several sub-problems, then try to develop a step-by-step procedure to solve them. Since language processing is involved, we would also list all the forms of text processing needed at each step.</p>
<p><em>This step-by-step processing of text is known as a NLP pipeline. It is the series of steps involved in building any NLP model.</em></p>
<p><figure>
  
    <img class="docimage" src="/Bits-and-Bytes-of-NLP/images/copied_from_nb/my_icons/topic_02.a.1.png" alt="">
    
    
</figure>
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The key stages in the pipeline are as follows:</p>
<ol>
<li>
<p>Data acquisition</p>
</li>
<li>
<p>Text cleaning</p>
</li>
<li>
<p>Pre-processing</p>
</li>
<li>
<p>Feature engineering</p>
</li>
<li>
<p>Modeling</p>
</li>
<li>
<p>Evaluation</p>
</li>
<li>
<p>Deployment</p>
</li>
<li>
<p>Monitoring and model updating</p>
</li>
</ol>
<p>Before we dive into NLP applications implementation the first and foremost thing is to get a clear picture about it’s pipeline. Hence, below are a detail overview about each component in it's pipeline. 
</p>
<div class="flash">
    <svg class="octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>The blog post on NLP pipeline is divided into 3 blog post. The first blog post covers the Data acquisition and Text Cleaning. Second blog post covers Pre-processing and Feature engineering and the 3rd blog post covers modeling, Evaluation, Deployment and Moniotring and model updating. 
</div>
<h1 id="DATA-ACQUISITION">
<a class="anchor" href="#DATA-ACQUISITION" aria-hidden="true"><span class="octicon octicon-link"></span></a>DATA ACQUISITION<a class="anchor-link" href="#DATA-ACQUISITION"> </a>
</h1>
<p>Data plays a major role in the NLP pipeline. Hence it's quite important that how we collect the relevant data for our NLP project.</p>
<p>Sometime it's easily available to us. But sometime extra effort need to be done to collect  these precious data.</p>
<h2 id="1).Scrape-web-pages">
<a class="anchor" href="#1).Scrape-web-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>1).Scrape web pages<a class="anchor-link" href="#1).Scrape-web-pages"> </a>
</h2>
<p>To create an application that can summarizes the top news into just 100 words .For that you need to scrape the data from the current affairs websites and webpages.</p>
<h2 id="2).Data-Augmentation">
<a class="anchor" href="#2).Data-Augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2).Data Augmentation<a class="anchor-link" href="#2).Data-Augmentation"> </a>
</h2>
<p>NLP has a bunch of techniques through which we can take a small dataset and use some tricks to create more data. These tricks are also called data augmentation, and they try to exploit language properties to create text that is syntactically similar to source text data. They may appear as hacks, but they work very well in practice. Let’s look at some of them:</p>
<h3 id="a).Back-translation">
<a class="anchor" href="#a).Back-translation" aria-hidden="true"><span class="octicon octicon-link"></span></a>a).Back translation<a class="anchor-link" href="#a).Back-translation"> </a>
</h3>
<p>Let say we have sentence s1 which is in French. We will translate it to other language (in this case English) and after translation it become sentence s2. Now we will translate this sentence s2 again to French and now it become s3. We’ll find that S1 and S3 are very similar in meaning but there is  slight variations. Now we can add S3 to our dataset.</p>
<h3 id="b).Replacing-Entities">
<a class="anchor" href="#b).Replacing-Entities" aria-hidden="true"><span class="octicon octicon-link"></span></a>b).Replacing Entities<a class="anchor-link" href="#b).Replacing-Entities"> </a>
</h3>
<p>To create more dataset we will replace the entities name with other entities. Let say s1 is "I want to go to New York", here we will replace New York with other entity name for e.g. New Jersey.</p>
<h3 id="c).Synonym-Replacement">
<a class="anchor" href="#c).Synonym-Replacement" aria-hidden="true"><span class="octicon octicon-link"></span></a>c).Synonym Replacement<a class="anchor-link" href="#c).Synonym-Replacement"> </a>
</h3>
<p>Randomly choose “k” words in a sentence that are not stop words. Replace these words with their synonyms.</p>
<h3 id="d).Bigram-flipping">
<a class="anchor" href="#d).Bigram-flipping" aria-hidden="true"><span class="octicon octicon-link"></span></a>d).Bigram flipping<a class="anchor-link" href="#d).Bigram-flipping"> </a>
</h3>
<p>Divide the sentence into bigrams. Take one bigram at random and flip it. For example: “I am going to the supermarket.” Here, we take the bigram “going to” and replace it with the flipped one: “to Going.”</p>
<h1 id="TEXT-CLEANING">
<a class="anchor" href="#TEXT-CLEANING" aria-hidden="true"><span class="octicon octicon-link"></span></a>TEXT CLEANING<a class="anchor-link" href="#TEXT-CLEANING"> </a>
</h1>
<p>After  collecting data it is also important that data need to be in the form that is understood by computer. Consider the text contains different symbols and words which doesn't convey meaning to the model while training. So we will remove them before feeding to the model in an efficient way. This method is called Data Cleaning. Different Text Cleaning process are as follows:</p>
<h2 id="HTML-tag-cleaning">
<a class="anchor" href="#HTML-tag-cleaning" aria-hidden="true"><span class="octicon octicon-link"></span></a>HTML tag cleaning<a class="anchor-link" href="#HTML-tag-cleaning"> </a>
</h2>
<p>Well when collecting the data we scrap through various web pages. Beautiful Soup and Scrapy, which provide a range of utilities to parse web pages.Hence the text we collect does not have any HTML tag in it.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">urllib.request</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://en.wikipedia.org/wiki/Artificial_intelligence"</span>
<span class="n">page</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span> <span class="c1"># connect to website</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">page</span> <span class="o">=</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"An error occured."</span><span class="p">)</span>
<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">page</span><span class="p">,</span> <span class="s1">'html.parser'</span><span class="p">)</span>
<span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">'^tocsection-'</span><span class="p">)</span>
<span class="n">content_lis</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s1">'li'</span><span class="p">,</span> <span class="n">attrs</span><span class="o">=</span><span class="p">{</span><span class="s1">'class'</span><span class="p">:</span> <span class="n">regex</span><span class="p">})</span>
<span class="n">content</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">li</span> <span class="ow">in</span> <span class="n">content_lis</span><span class="p">:</span>
    <span class="n">content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">li</span><span class="o">.</span><span class="n">getText</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['1 History', '2 Basics', '3 Challenges', '3.1 Reasoning, problem solving', '3.2 Knowledge representation', '3.3 Planning', '3.4 Learning', '3.5 Natural language processing', '3.6 Perception', '3.7 Motion and manipulation', '3.8 Social intelligence', '3.9 General intelligence', '4 Approaches', '4.1 Cybernetics and brain simulation', '4.2 Symbolic', '4.2.1 Cognitive simulation', '4.2.2 Logic-based', '4.2.3 Anti-logic or scruffy', '4.2.4 Knowledge-based', '4.3 Sub-symbolic', '4.3.1 Embodied intelligence', '4.3.2 Computational intelligence and soft computing', '4.4 Statistical', '4.5 Integrating the approaches', '5 Tools', '6 Applications', '7 Philosophy and ethics', '7.1 The limits of artificial general intelligence', '7.2 Ethical machines', '7.2.1 Artificial moral agents', '7.2.2 Machine ethics', '7.2.3 Malevolent and friendly AI', '7.3 Machine consciousness, sentience and mind', '7.3.1 Consciousness', '7.3.2 Computationalism and functionalism', '7.3.3 Strong AI hypothesis', '7.3.4 Robot rights', '7.4 Superintelligence', '7.4.1 Technological singularity', '7.4.2 Transhumanism', '8 Impact', '8.1 Risks of narrow AI', '8.2 Risks of general AI', '9 Regulation', '10 In fiction', '11 See also', '12 Explanatory notes', '13 References', '13.1 AI textbooks', '13.2 History of AI', '13.3 Other sources', '14 Further reading', '15 External links']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Unicode-Normalization:">
<a class="anchor" href="#Unicode-Normalization:" aria-hidden="true"><span class="octicon octicon-link"></span></a>Unicode Normalization:<a class="anchor-link" href="#Unicode-Normalization:"> </a>
</h2>
<p>While cleaning the data we may also encounter various Unicode characters, including symbols, emojis, and other graphic characters. To parse such non-textual symbols and special characters, we use Unicode normalization. This means that the text we see should be converted into some form of binary representation to store in a computer. This process is known as text encoding.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">emoji</span>
<span class="n">text</span> <span class="o">=</span> <span class="n">emoji</span><span class="o">.</span><span class="n">emojize</span><span class="p">(</span><span class="s2">"Python is fun :red_heart:"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Python is fun ❤
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Text</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf-8"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Text</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>b'Python is fun \xe2\x9d\xa4'
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Spelling-Correction">
<a class="anchor" href="#Spelling-Correction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Spelling Correction<a class="anchor-link" href="#Spelling-Correction"> </a>
</h2>
<p>The data that we have might have some spelling mistake because of fast typing the text or using short hand or slang that are used on social media like twitter. Using these data may not result in better prediction by our model therefore it is quite important to handle these data before feeding it to the model. we don’t have a robust method to fix this, but we still can make good attempts to mitigate the issue. Microsoft released a REST API that can be used in Python for potential spell checking.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="System-Specific-Error-Correction">
<a class="anchor" href="#System-Specific-Error-Correction" aria-hidden="true"><span class="octicon octicon-link"></span></a>System-Specific Error Correction<a class="anchor-link" href="#System-Specific-Error-Correction"> </a>
</h2>
<ul>
<li>
<p>What if we need to extract the data from the PDF. Different PDF documents are encoded differently, and sometimes, we may not be able to extract the full text, or the structure of the text may get messed up. There are several libraries, such as PyPDF, PDFMiner, etc., to extract text from PDF documents but they are far from perfect.</p>
</li>
<li>
<p>Another common source of textual data is scanned documents. Text extraction from scanned documents is typically done through optical character recognition (OCR), using libraries such as Tesseract.</p>
</li>
</ul>
<h1 id="Recap">
<a class="anchor" href="#Recap" aria-hidden="true"><span class="octicon octicon-link"></span></a>Recap<a class="anchor-link" href="#Recap"> </a>
</h1>
<p>The first step in the process of developing any NLP system is to collect data relevant to the given task. Even if we’re building a rule-based system, we still need some data to design and test our rules. The data we get is seldom(rarely) clean, and this is where text cleaning comes into play.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="footnotes"><p id="fn-1">1. Notes are compiled from <a href="https://www.oreilly.com/library/view/practical-natural-language/9781492054047/"> Practical Natural Language Processing: A Comprehensive Guide to Building Real-World NLP Systems</a> and  <a href="https://morioh.com/p/a7b8982e5a5a">morioh</a><a href="#fnref-1" class="footnote footnotes">↩</a></p></div>
<div class="footnotes"><p id="fn-2">2. If you face any problem or have any feedback/suggestions feel free to comment.<a href="#fnref-2" class="footnote footnotes">↩</a></p></div>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ShubhangiDabral13/Bits-and-Bytes-of-NLP"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/Bits-and-Bytes-of-NLP/nlp-pipeline/2020/12/26/_12_24_Building_an_NLP_Pipeline(PART_1).html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Bits-and-Bytes-of-NLP/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Bits-and-Bytes-of-NLP/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Bits-and-Bytes-of-NLP/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A technical blog which cover all Bits and Bytes of NLP.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/ShubhangiDabral13" title="ShubhangiDabral13"><svg class="svg-icon grey"><use xlink:href="/Bits-and-Bytes-of-NLP/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/Shubhi_Dabral" title="Shubhi_Dabral"><svg class="svg-icon grey"><use xlink:href="/Bits-and-Bytes-of-NLP/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
